# NUAM Exchange - Sistema de Gesti√≥n de Calificaciones Tributarias

## üìã Descripci√≥n del Proyecto
Este proyecto implementa una soluci√≥n de **Arquitectura de Microservicios** para la gesti√≥n, procesamiento y auditor√≠a de Calificaciones Tributarias del holding NUAM.

El sistema permite la ingesta de datos financieros (v√≠a carga manual o eventos as√≠ncronos), el c√°lculo de factores tributarios, la segregaci√≥n de datos por cliente (Multi-tenancy) y la notificaci√≥n proactiva de eventos, cumpliendo con est√°ndares de alta disponibilidad, seguridad y desacoplamiento.

## üèóÔ∏è Arquitectura de la Soluci√≥n

El sistema est√° orquestado mediante **Docker Compose** y se compone de los siguientes nodos:

### 1. Backend Core (`srv-django-backend`)
* **Tecnolog√≠a:** Python 3.11, Django 5.0.
* **Funci√≥n:** API REST, l√≥gica de negocio, c√°lculo de factores, gesti√≥n de usuarios y panel de administraci√≥n (Jazzmin).
* **Seguridad:** Implementa aislamiento de datos por `Broker` (Corredor). Un corredor no puede ver los datos de otro.
* **Servidor:** Gunicorn + WhiteNoise (para gesti√≥n eficiente de archivos est√°ticos).

### 2. Bus de Eventos (`kafka` + `zookeeper`)
* **Tecnolog√≠a:** Apache Kafka 7.4 (Confluent), Zookeeper.
* **Funci√≥n:** Columna vertebral de comunicaci√≥n as√≠ncrona. Desacopla la ingesta de datos del procesamiento para garantizar resiliencia.

### 3. Consumidor de Persistencia (`srv-kafka-consumer`)
* **Tecnolog√≠a:** Python Standalone.
* **Funci√≥n:** Escucha el t√≥pico `nuam_events`. Procesa los mensajes entrantes, valida la existencia del corredor y persiste la calificaci√≥n en la base de datos PostgreSQL utilizando el ORM de Django inyectado.

### 4. Servicio de Notificaciones (`srv-notifier`)
* **Tecnolog√≠a:** Python Standalone.
* **Funci√≥n:** Microservicio reactivo (Patr√≥n Fan-out). Escucha el mismo t√≥pico `nuam_events` y simula el env√≠o de correos electr√≥nicos de alerta a los corredores afectados.

### 5. Persistencia (`postgres`)
* **Tecnolog√≠a:** PostgreSQL 16.
* **Funci√≥n:** Almacenamiento relacional transaccional para usuarios, calificaciones y logs de auditor√≠a.

---

## üöÄ Instalaci√≥n y Despliegue Automatizado

Este proyecto incluye un script de despliegue (`deploy.sh`) que automatiza la construcci√≥n, migraci√≥n y configuraci√≥n del entorno.

### Prerrequisitos
* Docker y Docker Compose instalados.
* Python 3.x (para ejecutar scripts de simulaci√≥n localmente).

### Despliegue R√°pido
Para levantar el entorno completo, ejecute el script maestro:

```bash
# Dar permisos de ejecuci√≥n
chmod +x deploy.sh

# Opci√≥n 1: Despliegue est√°ndar (Mantiene datos existentes)
./deploy.sh

# Opci√≥n 2: Despliegue Nuclear (Borra base de datos y comienza desde cero - Recomendado para primera vez)
./deploy.sh --clean
````

El script se encargar√° de:

1.  Limpiar vol√∫menes corruptos (si se usa `--clean`).
2.  Construir los contenedores.
3.  Esperar a que la Base de Datos est√© disponible.
4.  Aplicar migraciones y recolectar est√°ticos.
5.  Crear un Superusuario por defecto (`admin` / `admin`).
6.  Ejecutar pruebas unitarias de integridad.

-----

## üñ•Ô∏è Uso del Sistema

### 1\. Panel de Administraci√≥n y Dashboard

Acceda a la interfaz web:

  * **URL:** `http://localhost:8000/`
  * **Login:** Use las credenciales `admin` / `admin`.
  * **Funcionalidades:**
      * **Dashboard Operativo:** Visualizaci√≥n de calificaciones y logs filtrados por Corredor.
      * **Carga Masiva:** Ingesta de archivos CSV.
      * **Panel Admin (`/admin`):** Gesti√≥n avanzada de Usuarios y creaci√≥n de Brokers (Tenants) con interfaz Jazzmin.

### 2\. Simulaci√≥n de Eventos de Bolsa (Kafka)

Para probar la integraci√≥n as√≠ncrona, se incluye un script productor que simula el env√≠o de datos desde la Bolsa de Comercio.

**Requisito:** Instalar librer√≠a cliente localmente:

```bash
pip install confluent-kafka
```

**Ejecuci√≥n:**

```bash
# Aseg√∫rese de tener "127.0.0.1 kafka" en su /etc/hosts o usar localhost
python srv-kafka-consumer/simulate_bolsa.py
```

*Resultado:* Los datos aparecer√°n autom√°ticamente en el Dashboard y se enviar√°n notificaciones por consola en el servicio `srv-notifier`.

### 3\. Pruebas de Carga (Locust)

Para validar la resiliencia del sistema bajo estr√©s:

```bash
# Iniciar Locust
python -m locust -f locustfile.py
```

Acceda a `http://localhost:8089` para configurar el enjambre de usuarios.

-----

## üß™ Pruebas Unitarias

El proyecto incluye tests automatizados para validar la segregaci√≥n de datos (Multi-tenancy):

```bash
docker-compose exec srv-django-backend python manage.py test api
```

-----

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as Clave

  * **Backend:** Django 5.0, Gunicorn.
  * **Frontend/Admin:** Django Templates, Jazzmin, WhiteNoise.
  * **Mensajer√≠a:** Confluent Kafka.
  * **Base de Datos:** PostgreSQL.
  * **Infraestructura:** Docker, Docker Compose.
  * **QA/Testing:** Locust, Django Test Framework.

-----

## üë• Autores

  * **Nicol√°s Anrique**
  * **Diego Ibeas**
  * **Camilo Nu√±ez**
  
### Agradecimientos Especiales

  * **H0P3** - *Asistencia T√©cnica & IA Copilot*

<!-- end list -->
